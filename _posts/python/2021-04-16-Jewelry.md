---
layout: post
title: Python decorators for data science pipelines
author: matt_sosna
---

When it comes to productizing data science, there's a lot of architecture *around* your core model or analysis that needs careful consideration. Maybe you have a model retrainer workflow that queries an API every night for raw data, processes that data, and then updates a model to generate forecasts for tomorrow. Unless you have a solid data engineering team, a pipeline like this can end up having many moving components, especially if you're generating models for customers with varying levels of data availability. (e.g. we don't want to keep a model if the $R^2$ is too low.)


Maybe one decorator on the other side could be to send your pickled model to one S3 bucket vs. another based on the model's accuracy? Or at least associate a tag with it...


Maybe your workflow queries an API every night at 2am, then processes the data and uses it to retrain a model that generates a forecast for tomorrow.

The main use case we'll cover is **input validation.** When building a complex pipeline, we want to "lock" the inputs at various stages. You could write a function that handles errors, e.g. some sort of private method like `_validate_inputs`, but it's often cleaner to move that logic outside the function as a decorator. Then you know anything you're reading inside the function is what you think it is.

This is also especially important when a user is involved. Let's imagine we have a class that formats a URL for querying data. We use a `DataParams` class that is effectively a template and converts inputs to values in the URL.

Somewhat similar to [data classes](https://towardsdatascience.com/data-classes-in-python-8d1a09c1294b).

One option is to write something like this:

```python
class DataParams:
    def __init__(self, start_date, end_date):
        self.start_date = start_date
        self.end_date = end_date
```

But what if we accidentally pass in a date that is a weirdly-formatted string rather than a `dt.datetime` object? Our `DataParams` class won't really work.

An alternative is to instantiate the values to `None`, then have specific functions for setting start and end date. Inside these functions, we could do type validation.

```python
class DataParams:

    def __init__(self):
        self.start_date = None
        self.end_date = None

    def set_start_date(self, start_date):
        assert isinstance(start_date, dt.datetime), \
            f"start_date must be dt.datetime"
        self.start_date = start_date

    def set_end_date(self, end_date):
        assert isinstance(end_date, dt.datetime), \
            f"end_date must be dt.datetime"
        self.end_date = end_date
```

While this works ok, it could be nicer to just be able to instantiate `DataParams` with all parameters at once and check our types there.


But what if the data isn't in the right format?


Or you get an unexpected input? Your

I created a package tentatively called `jewelry` and am looking for contributors. Have an idea for how to improve the functions I'm about to show you? Hit me up bro.

This post assumes you're somewhat familiar with **decorators**, or Python functions that *modify* other functions. Decorators serve as wrappers around a function, allowing us control over the inputs and outputs of a function without needing to modify the function itself. (For more detail, check out *this great post XXX* by XXX.)

## Jewelry

### `ArgChecker`
This is a class that we start by loading and instantiating. We can then use its `enforce_type_hints` method.

```python
from jewelry import ArgChecker
ac = ArgChecker()
```

#### `enforce_type_hints`
* Verify that inputs to a function match the type hints.

```python
def multiply(a, b):
    return a * b

@ac.enforce_type_hints
def safe_multiply(a: int, b: int):
    return a * b

# Good behavior
multiply(1, 2)       # 2
safe_multiply(1, 2)  # 2

# Diverges
multiply('1', 2)     # '11'
safe_multiply('1', 2)  # AssertionError: a is type <class 'str'>
```




### `DataChecker`
I guess this is kind of like Great Expectations, so I'd want to see how it differs... but could do something simple.

```python
def check_thing(df, cols):
    for col in cols:
        assert df[col].max() - df[col].min() > 5
```

#### `.colcheck`

```python
@ac.colcheck(df, ['a', 'b'])
def add_cols(df: pd.DataFrame):
    return df['a'] + df['b']
```

Makes sure that cols `a` and `b` are present, raises an `AssertionError` if not.


* `jewelry` is a Python repo I've created for this. Please contribute.
